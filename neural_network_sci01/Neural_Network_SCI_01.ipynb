{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ccde21b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (1.19.5)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0-py2.py3-none-any.whl\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-0.24.2-cp36-cp36m-win_amd64.whl (6.8 MB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from scikit-learn->sklearn) (1.19.5)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Using cached scipy-1.5.4-cp36-cp36m-win_amd64.whl (31.2 MB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-1.1.0 scikit-learn-0.24.2 scipy-1.5.4 sklearn-0.0 threadpoolctl-3.0.0\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-win_amd64.whl (8.7 MB)\n",
      "Collecting pytz>=2017.2\n",
      "  Using cached pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.1.5 pytz-2021.3\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.3.4-cp36-cp36m-win_amd64.whl (8.5 MB)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from matplotlib) (1.19.5)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.3.1-cp36-cp36m-win_amd64.whl (51 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-8.4.0-cp36-cp36m-win_amd64.whl (3.2 MB)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from matplotlib) (3.0.3)\n",
      "Requirement already satisfied: six in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "Installing collected packages: pillow, kiwisolver, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.3.4 pillow-8.4.0\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from seaborn) (1.19.5)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from seaborn) (3.3.4)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from seaborn) (1.5.4)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from seaborn) (1.1.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from matplotlib>=2.2->seaborn) (3.0.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from matplotlib>=2.2->seaborn) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.11.2\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.0-cp36-cp36m-win_amd64.whl (423.2 MB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting keras~=2.6\n",
      "  Using cached keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting clang~=5.0\n",
      "  Using cached clang-5.0.tar.gz (30 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Using cached absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.41.1-cp36-cp36m-win_amd64.whl (3.2 MB)\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Using cached tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from tensorflow) (0.37.0)\n",
      "Collecting h5py~=3.1.0\n",
      "  Using cached h5py-3.1.0-cp36-cp36m-win_amd64.whl (2.7 MB)\n",
      "Collecting six~=1.15.0\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.0-cp36-cp36m-win_amd64.whl (897 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Using cached wrapt-1.12.1-cp36-cp36m-win_amd64.whl\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting cached-property\n",
      "  Using cached cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.3.2-py2.py3-none-any.whl (155 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-2.0.2-py3-none-any.whl (288 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (58.0.4)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.1)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.7-py3-none-any.whl (38 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Collecting dataclasses\n",
      "  Using cached dataclasses-0.8-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
      "Building wheels for collected packages: clang\n",
      "  Building wheel for clang (setup.py): started\n",
      "  Building wheel for clang (setup.py): finished with status 'done'\n",
      "  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30692 sha256=3103f10b43df588da06e57c165bc567d8602ba7f3750a14150ea5b0105b671a9\n",
      "  Stored in directory: c:\\users\\dungm\\appdata\\local\\pip\\cache\\wheels\\22\\4c\\94\\0583f60c9c5b6024ed64f290cb2d43b06bb4f75577dc3c93a7\n",
      "Successfully built clang\n",
      "Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, typing-extensions, six, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, dataclasses, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, cached-property, absl-py, wrapt, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras, h5py, google-pasta, gast, flatbuffers, clang, astunparse, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.2\n",
      "    Uninstalling typing-extensions-3.10.0.2:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.2\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "Successfully installed absl-py-0.15.0 astunparse-1.6.3 cached-property-1.5.2 cachetools-4.2.4 charset-normalizer-2.0.7 clang-5.0 dataclasses-0.8 flatbuffers-1.12 gast-0.4.0 google-auth-2.3.2 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.41.1 h5py-3.1.0 idna-3.3 keras-2.6.0 keras-preprocessing-1.1.2 markdown-3.3.4 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.19.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.26.0 requests-oauthlib-1.3.0 rsa-4.7.2 six-1.15.0 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.6.0 tensorflow-estimator-2.6.0 termcolor-1.1.0 typing-extensions-3.7.4.3 urllib3-1.26.7 werkzeug-2.0.2 wrapt-1.12.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hdfdict\n",
      "  Downloading hdfdict-0.1.1alpha-py3-none-any.whl (3.5 kB)\n",
      "Requirement already satisfied: h5py in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from hdfdict) (3.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from hdfdict) (1.19.5)\n",
      "Requirement already satisfied: cached-property in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from h5py->hdfdict) (1.5.2)\n",
      "Installing collected packages: hdfdict\n",
      "Successfully installed hdfdict-0.1.1a0\n",
      "Collecting prettytable\n",
      "  Downloading prettytable-2.2.1-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from prettytable) (0.2.5)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from prettytable) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from importlib-metadata->prettytable) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from importlib-metadata->prettytable) (3.7.4.3)\n",
      "Installing collected packages: prettytable\n",
      "Successfully installed prettytable-2.2.1\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\dungm\\anaconda3\\envs\\nn01\\lib\\site-packages (from tqdm) (0.4.4)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.62.3\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install sklearn\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install tensorflow\n",
    "!pip install hdfdict\n",
    "!pip install prettytable\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9ff4526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hdfdict in c:\\users\\dungm\\anaconda3\\envs\\nn\\lib\\site-packages (0.1.1a0)\n",
      "Requirement already satisfied: numpy in c:\\users\\dungm\\anaconda3\\envs\\nn\\lib\\site-packages (from hdfdict) (1.17.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\dungm\\anaconda3\\envs\\nn\\lib\\site-packages (from hdfdict) (2.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\dungm\\anaconda3\\envs\\nn\\lib\\site-packages (from h5py->hdfdict) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "import math\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import cm\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "!pip install hdfdict\n",
    "import hdfdict\n",
    "from prettytable import PrettyTable\n",
    "from tqdm import tqdm,trange\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b804c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_orig, Y_train_orig), (X_test_orig, Y_test_orig) = mnist.load_data()\n",
    "\n",
    "# Preparing the data\n",
    "Y_tr_resh = Y_train_orig.reshape(60000, 1)\n",
    "Y_te_resh = Y_test_orig.reshape(10000, 1)\n",
    "Y_tr_T = to_categorical(Y_tr_resh, num_classes=10)\n",
    "Y_te_T = to_categorical(Y_te_resh, num_classes=10)\n",
    "y_tr = Y_tr_T.T\n",
    "y_te = Y_te_T.T\n",
    "\n",
    "\n",
    "# Flattening of inputs\n",
    "X_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n",
    "X_test_flatten = X_test_orig.reshape(X_test_orig.shape[0], -1).T\n",
    "\n",
    "# Preprocessing of Inputs\n",
    "X_tr = X_train_flatten.T / 255.\n",
    "X_te = X_test_flatten.T / 255.\n",
    "num_classes = y_tr.shape[0]\n",
    "m_tr = X_tr.shape[0]\n",
    "m_te = X_te.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e6202fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "  def forward(self):\n",
    "    return np.maximum(0,self)\n",
    "  \n",
    "  def backward(self):\n",
    "    self[self<=0] = 0\n",
    "    self[self>0] = 1\n",
    "    return self\n",
    "\n",
    "class Tanh:\n",
    "  def forward(self):\n",
    "    return np.tanh(self)\n",
    "\n",
    "  def backward(self):\n",
    "    return (1 - np.square(Tanh.forward(self)))\n",
    "\n",
    "class Sigmoid:\n",
    "  def forward(self):\n",
    "    return (1 / (1 + np.exp(-self)))\n",
    "  \n",
    "  def backward(self):\n",
    "    return (Sigmoid.forward(self)*(1-Sigmoid.forward(self)))\n",
    "\n",
    "class Softmax:\n",
    "  def forward(self):\n",
    "    soft = np.exp(self)/np.sum(np.exp(self),axis=0)\n",
    "    return soft\n",
    "\n",
    "  def backward(self):\n",
    "    return (Softmax.forward(self)*(1 - Softmax.forward(self))) \n",
    "\n",
    "class Sine:\n",
    "  def forward(self):\n",
    "    return np.sin(self)\n",
    "  \n",
    "  def backward(self):\n",
    "    return np.cos(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd26c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predict:\n",
    "  def __init__(self,A,threshold=0.5):\n",
    "    self.A = A\n",
    "    self.threshold = threshold\n",
    "  def __call__(self):\n",
    "    predictions = np.zeros((self.A.shape))\n",
    "    for g in range(0,self.A.shape[1]):\n",
    "      if self.A[:,g] >= self.threshold:\n",
    "        predictions[:,g] = 1\n",
    "    return predictions\n",
    "\n",
    "class PredictMulti:\n",
    "  def __init__(self,A):\n",
    "    self.A = A\n",
    "  def __call__(self):\n",
    "    predictions_multi = np.zeros(self.A.shape)\n",
    "    for v in range(0,self.A.shape[1]):\n",
    "      temp = max(self.A[:,v])\n",
    "      for w in range(0,self.A.shape[0]):\n",
    "        if self.A[w,v] == temp:\n",
    "          predictions_multi[w,v] = 1\n",
    "        else:\n",
    "          predictions_multi[w,v] = 0\n",
    "    return predictions_multi\n",
    "\n",
    "class Evaluate:\n",
    "  def __init__(self,y,preds):\n",
    "    self.y,self.preds = y,preds\n",
    "  def __call__(self):\n",
    "    accuracy = float(np.mean(self.preds==self.y,axis=1)*100)\n",
    "    return accuracy\n",
    "\n",
    "class EvaluateMulti:\n",
    "  def __init__(self,y,preds):\n",
    "    self.y,self.preds = y,preds\n",
    "  def __call__(self):\n",
    "    ones_array = np.ones(self.preds.shape)\n",
    "    temp1 = self.preds==ones_array\n",
    "    ind = []\n",
    "    for gee in range(0,temp1.shape[1]):\n",
    "      for jee in range(0,temp1.shape[0]):\n",
    "        if temp1[jee,gee] == True:\n",
    "          ind.append(jee)\n",
    "    ind_arr = np.array(ind)\n",
    "    y_list = []\n",
    "    for gee in range(0,self.y.shape[1]):\n",
    "      for jee in range(0,self.y.shape[0]):\n",
    "        if self.y[jee,gee] == 1:\n",
    "          y_list.append(jee)\n",
    "    y_arr = np.array(y_list)\n",
    "    accuracy = float(np.mean(ind_arr == y_arr.T))*100\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "class PrecisionRecall:\n",
    "  def __init__(self,A,y):\n",
    "    self.A,self.y = A,y\n",
    "  def __call__(self):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for i in range(0,self.y.shape[1]):\n",
    "      if ((self.A[0,i]==1)and(self.y[0,i]==1)):\n",
    "        tp = tp+1\n",
    "      if ((self.A[0,i]==1)and(self.y[0,i]==0)):\n",
    "        fp = fp+1\n",
    "      if (self.A[0,i]==0)and(self.y[0,i]==1):\n",
    "        fn = fn+1\n",
    "    prec = tp/(tp+fp)\n",
    "    rec = tp/(tp+fn)\n",
    "    f1 = (2*prec*rec)/(prec+rec)\n",
    "    return prec,rec,f1\n",
    "\n",
    "class PrecisionRecallMulti:\n",
    "  def __init__(self,A,y):\n",
    "    self.A,self.y = A,y\n",
    "  def __call__(self):\n",
    "    epsilon = 1e-5\n",
    "    tp_multi = {}\n",
    "    fp_multi = {}\n",
    "    fn_multi = {}\n",
    "    prec_multi = {}\n",
    "    rec_multi = {}\n",
    "    f1_multi = {}\n",
    "    num_classes = self.y.shape[0]\n",
    "    for r in range(0,num_classes):\n",
    "      tp_multi[\"class\" + str(r)] = 0\n",
    "      fp_multi[\"class\" + str(r)] = 0\n",
    "      fn_multi[\"class\" + str(r)] = 0\n",
    "    for c in range(0,self.y.shape[1]):\n",
    "      for g in range(0,self.y.shape[0]):\n",
    "        if ((self.A[g,c]==1) and (self.y[g,c]==1)):\n",
    "          tp_multi[\"class\" + str(g)] = tp_multi[\"class\" + str(g)] + 1\n",
    "        if ((self.A[g,c]==1) and (self.y[g,c]==0)):\n",
    "          fp_multi[\"class\" + str(g)] = fp_multi[\"class\" + str(g)] + 1\n",
    "        if ((self.A[g,c]==0) and (self.y[g,c]==1)):\n",
    "          fn_multi[\"class\" + str(g)] = fn_multi[\"class\" + str(g)] + 1\n",
    "    for n in range(0,num_classes):\n",
    "      prec_multi[\"class\" + str(n)] = tp_multi[\"class\" + str(n)] / (tp_multi[\"class\" + str(n)] + fp_multi[\"class\" + str(n)] + epsilon)\n",
    "      rec_multi[\"class\" + str(n)] = tp_multi[\"class\" + str(n)] / (tp_multi[\"class\" + str(n)] + fn_multi[\"class\" + str(n)] + epsilon)\n",
    "      f1_multi[\"class\" + str(n)] = (2*prec_multi[\"class\" + str(n)]*rec_multi[\"class\" + str(n)])/(prec_multi[\"class\" + str(n)] + rec_multi[\"class\" + str(n)] + epsilon)\n",
    "    return prec_multi,rec_multi,f1_multi\n",
    "\n",
    "class GradL1Reg:\n",
    "  def __init__(self,layers_arr):\n",
    "    self.layers_arr = layers_arr\n",
    "  def __call__(self):\n",
    "    for layer in self.layers_arr:\n",
    "      layer.grad_L1 = np.zeros(layer.weights.shape)\n",
    "      for p in range(0,layer.weights.shape[0]):\n",
    "        for n in range(0,layer.weights.shape[1]):\n",
    "          if layer.weights[p,n] > 0:\n",
    "            layer.grad_L1[p,n] = 1\n",
    "          else:\n",
    "            layer.grad_L1[p,n] = -1\n",
    "\n",
    "class CreateMiniBatches:\n",
    "  def __init__(self,X,y,mb_size):\n",
    "    self.X,self.y,self.mb_size = X,y,mb_size\n",
    "  def __call__(self):\n",
    "    m_ex = self.y.shape[1]\n",
    "    mini_batch = {}\n",
    "    num = m_ex//self.mb_size\n",
    "    if (m_ex%self.mb_size != 0):\n",
    "      f = 0\n",
    "      for p in range(0,num):\n",
    "        mini_batch[\"MB_X\" + str(p)] = self.X[f:(f+self.mb_size),:]\n",
    "        mini_batch[\"MB_Y\" + str(p)] = self.y[:,f:(f+self.mb_size)]\n",
    "        f = f + self.mb_size\n",
    "      mini_batch[\"MB_X\" + str(num)] = self.X[f:m_ex,:]\n",
    "      mini_batch[\"MB_Y\" + str(num)] = self.y[:,f:m_ex]\n",
    "      return mini_batch,num\n",
    "    else:\n",
    "      f = 0\n",
    "      for p in range(0,num-1):\n",
    "        mini_batch[\"MB_X\" + str(p)] = self.X[f:(f+self.mb_size),:]\n",
    "        mini_batch[\"MB_Y\" + str(p)] = self.y[:,f:(f+self.mb_size)]\n",
    "        f = f + self.mb_size\n",
    "      mini_batch[\"MB_X\" + str(num-1)] = self.X[f:m_ex,:]\n",
    "      mini_batch[\"MB_Y\" + str(num-1)] = self.y[:,f:m_ex]\n",
    "      return mini_batch,num-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91b1f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaticPlotHelpers:\n",
    "  def __init__(self,costs_tr,costs_cv,accu_tr_arr,accu_cv_arr):\n",
    "    self.costs_tr,self.costs_cv = costs_tr,costs_cv\n",
    "    self.accu_tr_arr,self.accu_cv_arr = accu_tr_arr,accu_cv_arr\n",
    "\n",
    "class AnimatePlotHelpers:\n",
    "  def __init__(self,x_ax,y_ax,X_lab,Y_lab,plot_title,leg,loca,plot_col,direc,freq):\n",
    "    self.x_ax,self.y_ax,self.X_lab,self.Y_lab = x_ax,y_ax,X_lab,Y_lab\n",
    "    self.plot_title,self.leg,self.loca,self.plot_col,self.direc,self.freq = plot_title,leg,loca,plot_col,direc,freq\n",
    "\n",
    "\n",
    "class PlotCostStatic(StaticPlotHelpers):\n",
    "  def __init__(self,costs_tr,costs_cv,accu_tr_arr,accu_cv_arr):\n",
    "    StaticPlotHelpers.__init__(self,costs_tr,costs_cv,accu_tr_arr,accu_cv_arr)\n",
    "  def __call__(self):\n",
    "    itera = np.arange(1,len(self.costs_tr)+1,1)\n",
    "    plt.xlabel('Number of Iterations')\n",
    "    plt.ylabel('Cost')\n",
    "    plt.title('Cost Function Variation')\n",
    "    plt.plot(itera,self.costs_tr,color='c',linewidth=2)\n",
    "    if len(self.costs_cv) != 0:\n",
    "      plt.plot(itera,self.costs_cv,color='#9ef705',linewidth=2)\n",
    "    plt.legend([\"Train\",\"Cross Val\"],loc='upper right')\n",
    "\n",
    "class PlotTrCvStatic(StaticPlotHelpers):\n",
    "  def __init__(self,costs_tr,costs_cv,accu_tr_arr,accu_cv_arr):\n",
    "    StaticPlotHelpers.__init__(self,costs_tr,costs_cv,accu_tr_arr,accu_cv_arr)\n",
    "  def __call__(self):\n",
    "    itera = np.arange(1,len(self.costs_tr)+1,1)\n",
    "    plt.xlabel('Number of Iterations')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Train - Cross Val Accuracy Curve')\n",
    "    plt.plot(itera,self.accu_tr_arr,color='m',linewidth=2)\n",
    "    if len(self.accu_cv_arr) != 0:\n",
    "      plt.plot(itera,self.accu_cv_arr,color='r',linewidth=2)\n",
    "    plt.legend([\"Train\",\"Cross Val\"],loc='lower right')\n",
    "\n",
    "class AnimatePlot(AnimatePlotHelpers):\n",
    "  def __init__(self,x_ax,y_ax,X_lab,Y_lab,plot_title,leg,loca,plot_col,direc,freq):\n",
    "    AnimatePlotHelpers.__init__(self,x_ax,y_ax,X_lab,Y_lab,plot_title,leg,loca,plot_col,direc,freq)\n",
    "  def __call__(self):\n",
    "    y_vals = self.y_ax\n",
    "    x_vals = self.x_ax\n",
    "    l = 0\n",
    "    for k in range(1,len(x_vals)+1):\n",
    "      plt.xlabel(self.X_lab)\n",
    "      plt.ylabel(self.Y_lab)\n",
    "      plt.title(self.plot_title)\n",
    "      plt.legend([self.leg],loc=self.loca)\n",
    "      plt.plot(x_vals[0:l],y_vals[0:l],color=self.plot_col)\n",
    "      l = l+1\n",
    "      if k%self.freq==0:\n",
    "        plt.savefig(self.direc + 'plot{}.png'.format(k//self.freq))\n",
    "    return\n",
    "\n",
    "class AnimatePlotMulti(AnimatePlotHelpers):\n",
    "  def __init__(self,x_ax,y_ax,X_lab,Y_lab,plot_title,leg,loca,plot_col,direc,freq):\n",
    "    AnimatePlotHelpers.__init__(self,x_ax,y_ax,X_lab,Y_lab,plot_title,leg,loca,plot_col,direc,freq)\n",
    "  def __call__(self):\n",
    "    x_vals = {}\n",
    "    y_vals = {}\n",
    "    for m in range(0,len(self.x_ax)):\n",
    "      x_vals[\"X\" + str(m)] = self.x_ax[m]\n",
    "    for g in range(0,len(self.y_ax)):\n",
    "      y_vals[\"Y\" + str(g)] = self.y_ax[g]\n",
    "    for h in range(0,len(self.leg)):\n",
    "      plt.plot([],[],color=self.plot_col[h],label = self.leg[h])\n",
    "    plt.legend(loc=self.loca)\n",
    "    l = 0\n",
    "    for k in range(1,len(self.x_ax[0])+1):\n",
    "      plt.xlabel(self.X_lab)\n",
    "      plt.ylabel(self.Y_lab)\n",
    "      plt.title(self.plot_title)\n",
    "      for d in range(0,len(self.x_ax)):\n",
    "        if len(x_vals[\"X\" + str(d)]) != 0:\n",
    "          plt.plot(x_vals[\"X\" + str(d)][0:l],y_vals[\"Y\" + str(d)][0:l],color=self.plot_col[d])\n",
    "      l = l+1\n",
    "      if k%self.freq==0:\n",
    "        plt.savefig(self.direc + 'plot{}.png'.format(k//self.freq))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbfaea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegularizationHelpers:\n",
    "  def __init__(self,layers_arr,lamb,m_exam):\n",
    "    self.layers_arr,self.lamb,self.m_exam = layers_arr,lamb,m_exam\n",
    "\n",
    "\n",
    "class L1Reg(RegularizationHelpers):\n",
    "  def __init__(self,layers_arr,lamb,m_exam):\n",
    "    RegularizationHelpers.__init__(self,layers_arr,lamb,m_exam)\n",
    "  def __call__(self):\n",
    "    temp_sum = 0\n",
    "    for layers in self.layers_arr:\n",
    "      temp_sum = temp_sum + ((self.lamb/self.m_exam)*(np.sum(np.sum(layers.weights))))\n",
    "      layers.grad_reg = ((self.lamb/self.m_exam)*(layers.grad_L1))\n",
    "    return temp_sum\n",
    "\n",
    "class L2Reg(RegularizationHelpers):\n",
    "  def __init__(self,layers_arr,lamb,m_exam):\n",
    "    RegularizationHelpers.__init__(self,layers_arr,lamb,m_exam)\n",
    "  def __call__(self):\n",
    "    temp_sum = 0\n",
    "    for layers in self.layers_arr:\n",
    "      temp_sum = temp_sum + ((self.lamb/(2*self.m_exam))*(np.sum(np.sum(np.square(layers.weights)))))\n",
    "      layers.grad_reg = ((self.lamb/self.m_exam)*(layers.weights))\n",
    "    return temp_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df47c985",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CostFunctionHelpers:\n",
    "  def __init__(self,y,A,layers_arr,lamb,reg=None):\n",
    "    self.y,self.A,self.layers_arr,self.lamb,self.reg = y,A,layers_arr,lamb,reg\n",
    "\n",
    "\n",
    "class BinaryCrossEntropy(CostFunctionHelpers):\n",
    "  def __init__(self,y,A,layers_arr,lamb,reg=None):\n",
    "    CostFunctionHelpers.__init__(self,y,A,layers_arr,lamb,reg=None)\n",
    "  def __call__(self):\n",
    "    if self.reg is not None:\n",
    "      if self.reg is \"L1\":\n",
    "        GradL1Reg(self.layers_arr)()\n",
    "        temp_sum = L1Reg(self.layers_arr,self.lamb,self.y.shape[1])()\n",
    "      if self.reg is \"L2\":\n",
    "        temp_sum = L2Reg(self.layers_arr,self.lamb,self.y.shape[1])()\n",
    "      cost = (-1/self.y.shape[1])*(np.sum(np.sum((self.y*np.log(self.A)) + ((1-self.y)*(np.log(1-self.A)))))) + temp_sum\n",
    "      grad = (-1/self.y.shape[1])*((self.y/self.A)-((1-self.y)/(1-self.A)))\n",
    "    else:\n",
    "      cost = (-1/self.y.shape[1])*(np.sum(np.sum((self.y*np.log(self.A)) + ((1-self.y)*(np.log(1-self.A))))))\n",
    "      grad = (-1/self.y.shape[1])*((self.y/self.A)-((1-self.y)/(1-self.A)))\n",
    "      for layers in self.layers_arr:\n",
    "        layers.grad_reg = 0\n",
    "    return cost,grad\n",
    "\n",
    "class CrossEntropy(CostFunctionHelpers):\n",
    "  def __init__(self,y,A,layers_arr,lamb,reg=None):\n",
    "    CostFunctionHelpers.__init__(self,y,A,layers_arr,lamb,reg=None)\n",
    "  def __call__(self):\n",
    "    if self.reg is not None:\n",
    "      if self.reg is \"L1\":\n",
    "        GradL1Reg(self.layers_arr)()\n",
    "        temp_sum = L1Reg(self.layers_arr,self.lamb,self.y.shape[1])()\n",
    "      if self.reg is \"L2\":\n",
    "        temp_sum = L2Reg(self.layers_arr,self.lamb,self.y.shape[1])()\n",
    "      cost = (-1/self.y.shape[1])*(np.sum(np.sum((self.y*np.log(self.A)))))\n",
    "      grad = (-1/self.y.shape[1])*((self.y/self.A))\n",
    "    else:\n",
    "      cost = (-1/self.y.shape[1])*(np.sum(np.sum((self.y*np.log(self.A)))))\n",
    "      grad = (-1/self.y.shape[1])*((self.y/self.A))\n",
    "      for layers in self.layers_arr:\n",
    "        layers.grad_reg = 0\n",
    "    return cost,grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de228094",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense:\n",
    "  \"\"\"\n",
    "      This layer is used for implemetation of Fully Connected Neural Networks\n",
    "      Methods:\n",
    "        Parameters Initialization\n",
    "        Forward Propagation\n",
    "        Backward Propagation\n",
    "  \"\"\"\n",
    "  def __init__(self,num_inputs,num_outputs,activation_fn,dropout=1.0,weights=None,bias=None,dZ=None,dW=None,db=None,dA=None,grad_L1=None,grad_reg=None):\n",
    "    self.num_inputs = num_inputs\n",
    "    self.num_outputs = num_outputs\n",
    "    self.activation_fn = activation_fn\n",
    "    self.dropout = dropout\n",
    "    self.dZ,self.dW,self.db,self.dA = dZ,dW,db,dA\n",
    "    self.grad_L1 = grad_L1\n",
    "    self.grad_reg = grad_reg\n",
    "    self.weights = weights\n",
    "    self.bias = bias\n",
    "    self.activ_dict = {\"relu\":[Relu.forward,Relu.backward,2],\n",
    "                       \"tanh\":[Tanh.forward,Tanh.backward,1],\n",
    "                       \"sigmoid\":[Sigmoid.forward,Sigmoid.backward,1],\n",
    "                       \"softmax\":[Softmax.forward,Softmax.backward,1],\n",
    "                       \"sine\":[Sine.forward,Sine.backward,6]}\n",
    "\n",
    "  def initialize_params(self):\n",
    "    self.weights = np.random.randn(self.num_outputs,self.num_inputs)*(np.sqrt(self.activ_dict[self.activation_fn][2]/self.num_inputs))\n",
    "    self.bias = np.random.randn(self.num_outputs, 1)*0.01\n",
    "    return self.weights,self.bias,self.grad_reg,self.grad_L1\n",
    "\n",
    "  def get_params(self):\n",
    "    return self.weights, self.bias\n",
    "    \n",
    "  def forw_prop(self,A_prev,train=True):\n",
    "    if train is False:\n",
    "      self.dropout = 1\n",
    "    self.outputs = np.dot(self.weights,A_prev) + self.bias\n",
    "    self.activations_temp = self.activ_dict[self.activation_fn][0](self.outputs)\n",
    "    self.activations = self.activations_temp*((np.random.rand(self.outputs.shape[0],self.outputs.shape[1]) < self.dropout)/self.dropout)\n",
    "    return self.outputs,self.activations\n",
    "\n",
    "  def back_prop(self,dA_prev,A_prev):\n",
    "    self.dZ = dA_prev*self.activ_dict[self.activation_fn][1](self.outputs)\n",
    "    self.dW = (np.dot(self.dZ,A_prev.T)) + self.grad_reg\n",
    "    self.db = np.sum(self.dZ,axis=1,keepdims = True)\n",
    "    self.dA = np.dot(self.weights.T,self.dZ)\n",
    "    return self.dZ,self.dW,self.db,self.dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56319f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizerHelpers:\n",
    "  def __init__(self,alpha,layers_arr,V_dict,S_dict,t):\n",
    "    self.alpha,self.layers_arr,self.V_dict,self.S_dict,self.t = alpha,layers_arr,V_dict,S_dict,t\n",
    "\n",
    "\n",
    "class GradientDescent(OptimizerHelpers):\n",
    "  def __init__(self,alpha,layers_arr,V_dict,S_dict,t):\n",
    "    OptimizerHelpers.__init__(self,alpha,layers_arr,V_dict,S_dict,t)\n",
    "  def __call__(self):\n",
    "    for layers in self.layers_arr:\n",
    "      layers.weights -= (self.alpha*layers.dW)\n",
    "      layers.bias -= (self.alpha*layers.db)\n",
    "\n",
    "class Momentum(OptimizerHelpers):\n",
    "  def __init__(self,alpha,layers_arr,V_dict,S_dict,t):\n",
    "    OptimizerHelpers.__init__(self,alpha,layers_arr,V_dict,S_dict,t)\n",
    "  def __call__(self):\n",
    "    beta1 = 0.9\n",
    "    for h in range(1,len(self.layers_arr)+1):\n",
    "      self.V_dict[\"Vdw\" + str(h)] = (beta1*self.V_dict[\"Vdw\" + str(h)]) + ((1-beta1)*self.layers_arr[h-1].dW)\n",
    "      self.V_dict[\"Vdb\" + str(h)] = (beta1*self.V_dict[\"Vdb\" + str(h)]) + ((1-beta1)*self.layers_arr[h-1].db)\n",
    "    for g in range(1,len(self.layers_arr)+1):\n",
    "      self.layers_arr[g-1].weights -= (self.alpha*self.V_dict[\"Vdw\" + str(g)])\n",
    "      self.layers_arr[g-1].bias -= (self.alpha*self.V_dict[\"Vdb\" + str(g)])\n",
    "\n",
    "class RMSProp(OptimizerHelpers):\n",
    "  def __init__(self,alpha,layers_arr,V_dict,S_dict,t):\n",
    "    OptimizerHelpers.__init__(self,alpha,layers_arr,V_dict,S_dict,t)\n",
    "  def __call__(self):\n",
    "    beta2 = 0.999\n",
    "    epsilon = 1e-8\n",
    "    for h in range(1,len(self.layers_arr)+1):\n",
    "      self.S_dict[\"Sdw\" + str(h)] = (beta2*self.S_dict[\"Sdw\" + str(h)]) + ((1-beta2)*np.square(self.layers_arr[h-1].dW))\n",
    "      self.S_dict[\"Sdb\" + str(h)] = (beta2*self.S_dict[\"Sdb\" + str(h)]) + ((1-beta2)*np.square(self.layers_arr[h-1].db))\n",
    "    for g in range(1,len(self.layers_arr)+1):\n",
    "      self.layers_arr[g-1].weights -= ((self.alpha*self.layers_arr[g-1].dW)/(np.sqrt(self.S_dict[\"Sdw\" + str(g)]) + epsilon))\n",
    "      self.layers_arr[g-1].bias -= ((self.alpha*self.layers_arr[g-1].db)/(np.sqrt(self.S_dict[\"Sdb\" + str(g)]) + epsilon))\n",
    "\n",
    "class Adam(OptimizerHelpers):\n",
    "  def __init__(self,alpha,layers_arr,V_dict,S_dict,t):\n",
    "    OptimizerHelpers.__init__(self,alpha,layers_arr,V_dict,S_dict,t)\n",
    "  def __call__(self):\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    epsilon = 1e-8\n",
    "    S_dict_corr = {}\n",
    "    V_dict_corr = {}\n",
    "    for h in range(1,len(self.layers_arr)+1):\n",
    "      self.V_dict[\"Vdw\" + str(h)] = (beta1*self.V_dict[\"Vdw\" + str(h)]) + ((1-beta1)*self.layers_arr[h-1].dW)\n",
    "      self.V_dict[\"Vdb\" + str(h)] = (beta1*self.V_dict[\"Vdb\" + str(h)]) + ((1-beta1)*self.layers_arr[h-1].db)\n",
    "    for u in range(1,len(self.layers_arr)+1):\n",
    "      self.S_dict[\"Sdw\" + str(u)] = (beta2*self.S_dict[\"Sdw\" + str(u)]) + ((1-beta2)*np.square(self.layers_arr[u-1].dW))\n",
    "      self.S_dict[\"Sdb\" + str(u)] = (beta2*self.S_dict[\"Sdb\" + str(u)]) + ((1-beta2)*np.square(self.layers_arr[u-1].db))\n",
    "    for n in range(1,len(self.layers_arr)+1):\n",
    "      S_dict_corr[\"Sdw\" + str(n)] = self.S_dict[\"Sdw\" + str(n)]/(1 - np.power(beta2,self.t))\n",
    "      S_dict_corr[\"Sdb\" + str(n)] = self.S_dict[\"Sdb\" + str(n)]/(1 - np.power(beta2,self.t))\n",
    "      V_dict_corr[\"Vdw\" + str(n)] = self.V_dict[\"Vdw\" + str(n)]/(1 - np.power(beta1,self.t))\n",
    "      V_dict_corr[\"Vdb\" + str(n)] = self.V_dict[\"Vdb\" + str(n)]/(1 - np.power(beta1,self.t))\n",
    "    for g in range(1,len(self.layers_arr)+1):\n",
    "      self.layers_arr[g-1].weights -= ((self.alpha*V_dict_corr[\"Vdw\" + str(g)])/(np.sqrt(S_dict_corr[\"Sdw\" + str(g)]) + epsilon))\n",
    "      self.layers_arr[g-1].bias -= ((self.alpha*V_dict_corr[\"Vdb\" + str(g)])/(np.sqrt(S_dict_corr[\"Sdb\" + str(g)]) + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b71e9eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "  \"\"\"\n",
    "      Binds all the other classes together and contains methods for adding layers,\n",
    "      training the network and testing the network\n",
    "      Methods:\n",
    "        Add\n",
    "        Fit\n",
    "        Test\n",
    "  \"\"\" \n",
    "  def __init__(self,X_tr,y_tr,X_te,y_te,X_cv,y_cv):\n",
    "    self.X_tr, self.y_tr = X_tr, y_tr\n",
    "    self.X_te, self.y_te = X_te, y_te\n",
    "    self.X_cv, self.y_cv = X_cv, y_cv\n",
    "    self.layer_names = []\n",
    "    self.layer_names_arr = []\n",
    "    self.activations_cache = None\n",
    "    self.params = None\n",
    "    self.arch = {}\n",
    "    self.accu_tr_arr = None\n",
    "    self.cost_tr_arr = None\n",
    "    self.accu_cv_arr = None\n",
    "    self.cost_cv_arr = None\n",
    "    self.lr = None\n",
    "    self.epochs = None\n",
    "\n",
    "  def add(self,layer_name,num_inputs,num_outputs,act_fn,dropout=1):\n",
    "    self.layer_names_arr.append(layer_name)\n",
    "    self.arch[str(layer_name)] = [layer_name.encode('utf8'),num_inputs,num_outputs,act_fn.encode('utf8'),dropout]\n",
    "    layer_name = Dense(num_inputs,num_outputs,act_fn,dropout)\n",
    "    Dense.initialize_params(layer_name)\n",
    "    self.layer_names.append(layer_name)\n",
    "  \n",
    "  def reset(self):\n",
    "    self.layer_names = []\n",
    "    self.arch = {}\n",
    "    self.layer_names_arr = []\n",
    "    return self.layer_names,self.arch,self.layer_names_arr\n",
    "\n",
    "  def params_dict(self,print_params):\n",
    "    self.params = {}\n",
    "    hee = 1\n",
    "    for layer in self.layer_names:\n",
    "      self.params[\"W\" + str(hee)],self.params[\"b\" + str(hee)] = Dense.get_params(layer)\n",
    "      hee += 1\n",
    "    if print_params is True:\n",
    "      print(self.params)\n",
    "      return self.params\n",
    "    else:\n",
    "      return self.params\n",
    "\n",
    "  def forward_prop(self,X,train_model=True):\n",
    "    self.activations_cache = {}\n",
    "    self.activations_cache = {\"A0\":X.T}\n",
    "    temp_A = X.T\n",
    "    p = 1\n",
    "    for layer in self.layer_names:\n",
    "      _,temp_A = Dense.forw_prop(layer,temp_A,train_model)\n",
    "      self.activations_cache[\"A\" + str(p)] = temp_A\n",
    "      p += 1\n",
    "    return self.activations_cache\n",
    "\n",
    "  def backward_prop(self,y,prob_type,activations_cache,lamb,reg):\n",
    "    prob_type_dict = {\"Binary\":[BinaryCrossEntropy,PrecisionRecall,Predict,Evaluate],\n",
    "                      \"Multi\":[CrossEntropy,PrecisionRecallMulti,PredictMulti,EvaluateMulti]}\n",
    "    _,temp_dA = prob_type_dict[prob_type][0](y,activations_cache[\"A\" + str(len(self.layer_names))],self.layer_names,lamb,reg)()\n",
    "    l = 1\n",
    "    for layer in reversed(self.layer_names):\n",
    "      _,layer.dW,layer.db,temp_dA = Dense.back_prop(layer,temp_dA,self.activations_cache[\"A\" + str(len(self.layer_names)-l)])\n",
    "      l += 1\n",
    "  \n",
    "  def fit(self,X,y,alpha,num_iter,optim,prob_type,mb,reg=None,lamb=None,alpha_decay=False,print_cost=True,callback=None):\n",
    "    self.lr = alpha\n",
    "    if (num_iter > 100) and (num_iter <= 1000):\n",
    "      freq = 10\n",
    "    elif num_iter > 1000:\n",
    "      freq = 50\n",
    "    elif (num_iter <= 100):\n",
    "      freq = 1\n",
    "    params = self.params_dict(print_params=False)\n",
    "    V_dict = {}\n",
    "    S_dict = {}\n",
    "    mini_batches,num = CreateMiniBatches(X,y,mb)()\n",
    "    self.accu_tr_arr = []\n",
    "    self.cost_tr_arr = []\n",
    "    self.accu_cv_arr = []\n",
    "    self.cost_cv_arr = []\n",
    "    for k in range(1,len(self.layer_names)+1):\n",
    "      V_dict[\"Vdw\" + str(k)] = np.zeros(params[\"W\" + str(k)].shape)\n",
    "      V_dict[\"Vdb\" + str(k)] = np.zeros(params[\"b\" + str(k)].shape)\n",
    "      S_dict[\"Sdw\" + str(k)] = np.zeros(params[\"W\" + str(k)].shape)\n",
    "      S_dict[\"Sdb\" + str(k)] = np.zeros(params[\"b\" + str(k)].shape)\n",
    "    optim_dict = {\"GD\":[GradientDescent,None,None,0],\n",
    "                  \"Momentum\":[Momentum,V_dict,None,0],\n",
    "                  \"RMSprop\":[RMSProp,None,S_dict,0],\n",
    "                  \"Adam\":[Adam,V_dict,S_dict,0]}\n",
    "    prob_type_dict = {\"Binary\":[BinaryCrossEntropy,PrecisionRecall,Predict,Evaluate],\n",
    "                      \"Multi\":[CrossEntropy,PrecisionRecallMulti,PredictMulti,EvaluateMulti]}\n",
    "\n",
    "    for i in range(1,num_iter+1):\n",
    "      params_plot = self.params_dict(print_params=False)\n",
    "      if alpha_decay is True:\n",
    "        alpha = (np.power(0.95,i))*self.lr\n",
    "      for vee in tqdm(range(0,num+1),file=sys.stdout):\n",
    "        activations_dict = self.forward_prop(mini_batches[\"MB_X\" + str(vee)])\n",
    "        self.backward_prop(mini_batches[\"MB_Y\" + str(vee)],prob_type,activations_dict,lamb,reg)\n",
    "        optim_dict[optim][0](alpha,self.layer_names,optim_dict[optim][1],optim_dict[optim][2],optim_dict[optim][3]+i)()\n",
    "        time.sleep(0.005)\n",
    "      act_tr = self.forward_prop(X)\n",
    "      cost_tr,_ = prob_type_dict[prob_type][0](y,act_tr[\"A\" + str(len(self.layer_names))],self.layer_names,lamb,reg)()\n",
    "      preds = prob_type_dict[prob_type][2](act_tr[\"A\" + str(len(self.layer_names))])()\n",
    "      accu_tr = prob_type_dict[prob_type][3](y,preds)()\n",
    "      self.accu_tr_arr.append(accu_tr)\n",
    "      self.cost_tr_arr.append(cost_tr)\n",
    "      if self.X_cv is not None:\n",
    "        act_cv = self.forward_prop(self.X_cv)\n",
    "        cost_cv,_ = prob_type_dict[prob_type][0](self.y_cv,act_cv[\"A\" + str(len(self.layer_names))],self.layer_names,lamb,reg)()\n",
    "        preds_cv = prob_type_dict[prob_type][2](act_cv[\"A\" + str(len(self.layer_names))])()\n",
    "        accu_cv = prob_type_dict[prob_type][3](self.y_cv,preds_cv)()\n",
    "        self.accu_cv_arr.append(accu_cv)\n",
    "        self.cost_cv_arr.append(cost_cv)\n",
    "      if ((i%1==0) and print_cost==True):\n",
    "        if self.X_cv is None:\n",
    "          print(\"Iteration \" + str(i) + \" \" + \"train_cost: \" + str(np.round(cost_tr,6)) + \" --- \" + \"train_acc: \" + str(np.round(accu_tr,3)))\n",
    "        else:\n",
    "          print(\"Iteration \" + str(i) + \" \" + \"train_cost: \" + str(np.round(cost_tr,6)) + \" --- \" + \"train_acc: \" + str(np.round(accu_tr,3)) + \" --- \" + \"val_cost: \" + str(np.round(cost_cv,6)) + \" --- \" + \"val_accu: \" + str(np.round(accu_cv,3)))\n",
    "      if (i % 1 == 0):\n",
    "        if (callback is not None):\n",
    "          callback(i, params_plot)\n",
    "\n",
    "  def save_model(self,fname):\n",
    "    params = self.params_dict(print_params=False)\n",
    "    archi = self.arch\n",
    "    model_dict = {\"Parameters\":params,\"Architecture\":archi}\n",
    "    hdfdict.dump(model_dict,fname)\n",
    "    print(\"Model saved!\")\n",
    "\n",
    "  def load_model(self,fname):\n",
    "    print(\"Model loading....\")\n",
    "    model_dict = dict(hdfdict.load(fname))\n",
    "    params_dict = model_dict[\"Parameters\"]\n",
    "    arch_dict = model_dict[\"Architecture\"]\n",
    "    self.reset()\n",
    "    for key in arch_dict:\n",
    "      self.add(arch_dict[key][0].decode('utf8'),int(arch_dict[key][1]),int(arch_dict[key][2]),arch_dict[key][3].decode('utf8'),int(arch_dict[key][4]))\n",
    "    dee = 1\n",
    "    for layer in self.layer_names:\n",
    "      layer.weights = params_dict[\"W\" + str(dee)]\n",
    "      layer.bias = params_dict[\"b\" + str(dee)]\n",
    "      dee += 1\n",
    "    print(\"Model loaded!\")\n",
    "\n",
    "  def plot(self,type_func,animate=False,direc=None):\n",
    "    itera = np.arange(1,len(self.cost_tr_arr)+1)\n",
    "    if (len(itera) > 100) and (len(itera) <= 1000):\n",
    "      freq = 10\n",
    "    elif len(itera) > 1000:\n",
    "      freq = 50\n",
    "    elif (len(itera) <= 100):\n",
    "      freq = 1\n",
    "    plot_dict = {\"Cost\":[PlotCostStatic,AnimatePlotMulti,self.cost_tr_arr,self.cost_cv_arr,'Costs','Train-Cross Val Costs Curve','upper right',['c','#9ef705'],AnimatePlot,\"Costs\",\"Cost Function Curve\"],\n",
    "                 \"Accuracy\":[PlotTrCvStatic,AnimatePlotMulti,self.accu_tr_arr,self.accu_cv_arr,'Accuracy','Train-Cross Val Accuracy Curve','lower right',['m','r'],AnimatePlot,\"Accuracy\",\"Accuracy Curve\"]}\n",
    "    if animate is False:\n",
    "      plot_dict[type_func][0](self.cost_tr_arr,self.cost_cv_arr,self.accu_tr_arr,self.accu_cv_arr)()\n",
    "    else:\n",
    "      if len(self.cost_cv_arr) != 0:\n",
    "        plot_dict[type_func][1]([itera,itera],[plot_dict[type_func][2],plot_dict[type_func][3]],'Number of Iterations',plot_dict[type_func][4],plot_dict[type_func][5],['Train', 'Cross Val'],plot_dict[type_func][6],plot_dict[type_func][7],direc,freq)()\n",
    "      else:\n",
    "        plot_dict[type_func][8](itera,plot_dict[type_func][2],\"Number of Iterations\",plot_dict[type_func][9],plot_dict[type_func][10],\"Train\",plot_dict[type_func][6],plot_dict[type_func][7][0],direc,freq)()\n",
    "      print(\"Go to your directory to find the images! Feed them to a GIF creator to animate them!\")\n",
    "\n",
    "\n",
    "  def summary(self):\n",
    "    tab = PrettyTable()\n",
    "    tab.field_names = [\"Layer Number\",\"Layer Name\",\"Inputs\",\"Outputs\",\"Activation\",\"Dropout\",\"Number of Parameters\"]\n",
    "    yee = 1\n",
    "    total_params = 0\n",
    "    for layer in self.layer_names:\n",
    "      total_params += (layer.weights.shape[0]*layer.weights.shape[1])+len(layer.bias)\n",
    "      tab.add_row([str(yee),self.layer_names_arr[yee-1],layer.weights.shape[1],layer.weights.shape[0],layer.activation_fn,layer.dropout,str((layer.weights.shape[0]*layer.weights.shape[1])+len(layer.bias))])\n",
    "      yee += 1\n",
    "    print(tab)\n",
    "    print(\"Total number of trainable Parameters: \" + str(total_params))\n",
    "\n",
    "  def test(self,X,y,prob_type,training=False,print_values=True):\n",
    "    prob_type_dict = {\"Binary\":[BinaryCrossEntropy,PrecisionRecall,Predict,Evaluate],\n",
    "                      \"Multi\":[CrossEntropy,PrecisionRecallMulti,PredictMulti,EvaluateMulti]}\n",
    "    act_te = self.forward_prop(X,training)\n",
    "    predictions_te = prob_type_dict[prob_type][2](act_te[\"A\" + str(len(self.layer_names))])()\n",
    "    accu_te = prob_type_dict[prob_type][3](y,predictions_te)()\n",
    "    prec_te,rec_te,f1_te = prob_type_dict[prob_type][1](predictions_te,y)()\n",
    "    tab = PrettyTable()\n",
    "    if prob_type == \"Multi\":\n",
    "      tab.field_names = [\"Class\",\"Precision\",\"Recall\",\"F1\"]\n",
    "      for hee in range(0,y.shape[0]):\n",
    "        tab.add_row([hee,prec_te[\"class\" + str(hee)],rec_te[\"class\" + str(hee)],f1_te[\"class\" + str(hee)]])\n",
    "      if print_values is True:\n",
    "        print(tab)\n",
    "        print(\"Test Accuracy: \" + str(accu_te))\n",
    "    if prob_type == \"Binary\":\n",
    "      tab.field_names = [\"Precision\",\"Recall\",\"F1\"]\n",
    "      tab.add_row([str(prec_te),str(rec_te),str(f1_te)])\n",
    "      if print_values is True:\n",
    "        print(tab)\n",
    "        print(\"Test Accuracy: \" + str(accu_te))\n",
    "    if print_values is not True:\n",
    "      return accu_te,prec_te,rec_te,f1_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a84b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(X_tr,y_tr,X_te,y_te,None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02048693",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset()\n",
    "model.add(\"dense1\",X_tr.shape[1],500,\"relu\")\n",
    "model.add(\"dense2\",500,250,\"relu\")\n",
    "model.add(\"dense3\",250,150,\"relu\")\n",
    "model.add(\"dense4\",150,100,\"sine\")\n",
    "model.add(\"dense5\",100,60,\"sine\")\n",
    "model.add(\"dense6\",60,30,\"relu\")\n",
    "model.add(\"dense7\",30,15,\"tanh\")\n",
    "model.add(\"dense8\",15,10,\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23f5c2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [00:07<00:00,  3.99it/s]\n",
      "Iteration 1 train_cost: 1.056352 --- train_acc: 78.948\n",
      "100%|| 30/30 [00:07<00:00,  3.88it/s]\n",
      "Iteration 2 train_cost: 0.799579 --- train_acc: 90.395\n",
      "100%|| 30/30 [00:07<00:00,  3.87it/s]\n",
      "Iteration 3 train_cost: 0.694194 --- train_acc: 93.495\n",
      "100%|| 30/30 [00:07<00:00,  3.84it/s]\n",
      "Iteration 4 train_cost: 0.63278 --- train_acc: 94.722\n",
      "100%|| 30/30 [00:07<00:00,  3.84it/s]\n",
      "Iteration 5 train_cost: 0.586633 --- train_acc: 95.417\n",
      "100%|| 30/30 [00:07<00:00,  3.85it/s]\n",
      "Iteration 6 train_cost: 0.548297 --- train_acc: 95.9\n",
      "100%|| 30/30 [00:07<00:00,  3.81it/s]\n",
      "Iteration 7 train_cost: 0.516041 --- train_acc: 96.353\n",
      "100%|| 30/30 [00:07<00:00,  3.86it/s]\n",
      "Iteration 8 train_cost: 0.491236 --- train_acc: 96.663\n",
      "100%|| 30/30 [00:07<00:00,  3.80it/s]\n",
      "Iteration 9 train_cost: 0.470687 --- train_acc: 96.943\n",
      "100%|| 30/30 [00:07<00:00,  3.83it/s]\n",
      "Iteration 10 train_cost: 0.452359 --- train_acc: 97.203\n",
      "100%|| 30/30 [00:07<00:00,  3.88it/s]\n",
      "Iteration 11 train_cost: 0.435254 --- train_acc: 97.417\n",
      "100%|| 30/30 [00:07<00:00,  3.84it/s]\n",
      "Iteration 12 train_cost: 0.419775 --- train_acc: 97.62\n",
      "100%|| 30/30 [00:07<00:00,  3.75it/s]\n",
      "Iteration 13 train_cost: 0.405867 --- train_acc: 97.828\n",
      "100%|| 30/30 [00:07<00:00,  3.81it/s]\n",
      "Iteration 14 train_cost: 0.392822 --- train_acc: 97.945\n",
      "100%|| 30/30 [00:07<00:00,  3.79it/s]\n",
      "Iteration 15 train_cost: 0.380663 --- train_acc: 98.072\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_tr,y_tr,0.0005,15,\"Adam\",\"Multi\",mb=2048,alpha_decay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b682381b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot(\"Cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac3022cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot(\"Accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d177dd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dungm\\Desktop\\neural_network_sci01\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\dungm\\Desktop\\neural_network_sci01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03a17f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dungm\\anaconda3\\envs\\nn\\lib\\site-packages\\hdfdict\\hdfdict.py:8: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  hdf = h5py.File(hdf)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.save_model('mnist_01.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dd33cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(X_tr,y_tr,X_te,y_te,None,None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcdb51ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loading....\n",
      "Model loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dungm\\anaconda3\\envs\\nn\\lib\\site-packages\\hdfdict\\hdfdict.py:36: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  d[k] = v.value\n"
     ]
    }
   ],
   "source": [
    "model1.load_model('mnist_01.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f3aee6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+--------+---------+------------+---------+----------------------+\n",
      "| Layer Number | Layer Name | Inputs | Outputs | Activation | Dropout | Number of Parameters |\n",
      "+--------------+------------+--------+---------+------------+---------+----------------------+\n",
      "|      1       |   dense1   |  784   |   500   |    relu    |    1    |        392500        |\n",
      "|      2       |   dense2   |  500   |   250   |    relu    |    1    |        125250        |\n",
      "|      3       |   dense3   |  250   |   150   |    relu    |    1    |        37650         |\n",
      "|      4       |   dense4   |  150   |   100   |    sine    |    1    |        15100         |\n",
      "|      5       |   dense5   |  100   |    60   |    sine    |    1    |         6060         |\n",
      "|      6       |   dense6   |   60   |    30   |    relu    |    1    |         1830         |\n",
      "|      7       |   dense7   |   30   |    15   |    tanh    |    1    |         465          |\n",
      "|      8       |   dense8   |   15   |    10   |  softmax   |    1    |         160          |\n",
      "+--------------+------------+--------+---------+------------+---------+----------------------+\n",
      "Total number of trainable Parameters: 579015\n"
     ]
    }
   ],
   "source": [
    "model1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f778ee2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+\n",
      "| Class |     Precision      |       Recall       |         F1         |\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "|   0   | 0.9856996834964282 | 0.9846938675031238 | 0.9851915188097665 |\n",
      "|   1   | 0.9772329161363142 | 0.9832599032311903 | 0.9802321456130549 |\n",
      "|   2   | 0.9356343196302769 | 0.9718992153885735 | 0.953417046002362  |\n",
      "|   3   | 0.9709709612515419 | 0.9603960300950888 | 0.9656495450672284 |\n",
      "|   4   | 0.9742533370313766 | 0.9633401123896119 | 0.9687609912876886 |\n",
      "|   5   | 0.9706546165840337 | 0.9641255497295342 | 0.967374066816425  |\n",
      "|   6   | 0.9697285911301817 | 0.9697285911301817 | 0.969723591155962  |\n",
      "|   7   | 0.9685658058097661 | 0.9591439595414012 | 0.9638268577814313 |\n",
      "|   8   | 0.9451219416146145 | 0.9548254522091842 | 0.9499439179304956 |\n",
      "|   9   | 0.9636730477934102 | 0.9464816556344732 | 0.9549949908811737 |\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "Test Accuracy: 96.6\n"
     ]
    }
   ],
   "source": [
    "model1.test(X_te,y_te,\"Multi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41482b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "GRID_X_START = 2.5\n",
    "GRID_X_END = -1.25\n",
    "GRID_Y_START = 1.5\n",
    "GRID_Y_END = -1\n",
    "OUTPUT_DIR = \"/content/drive/My Drive/Colab Notebooks/nn_visuals/moons1_foo\"\n",
    "grid = np.mgrid[GRID_X_START:GRID_X_END:100j,GRID_X_START:GRID_Y_END:100j]\n",
    "grid_2d = grid.reshape(2,-1)\n",
    "XX, YY = grid\n",
    "def make_plot(X, y, plot_name, file_name=None, XX=None, YY=None, preds=None, dark=False):\n",
    "    if (dark):\n",
    "        plt.style.use('dark_background')\n",
    "    else:\n",
    "        sns.set_style(\"whitegrid\")\n",
    "    plt.figure(figsize=(16,12))\n",
    "    axes = plt.gca()\n",
    "    axes.set(xlabel=\"$X_1$\", ylabel=\"$X_2$\")\n",
    "    plt.title(plot_name, fontsize=30)\n",
    "    plt.subplots_adjust(left=0.20)\n",
    "    plt.subplots_adjust(right=0.80)\n",
    "    if(XX is not None and YY is not None and preds is not None):\n",
    "        plt.contourf(XX, YY, preds.reshape(XX.shape), 25, alpha = 1, cmap=cm.Spectral)\n",
    "        plt.contour(XX, YY, preds.reshape(XX.shape), levels=[.5], cmap=\"Greys\", vmin=0, vmax=.6)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y.ravel(), s=40, cmap=plt.cm.Spectral, edgecolors='black')\n",
    "    if(file_name):\n",
    "        plt.savefig(file_name)\n",
    "        plt.close()\n",
    "import os\n",
    "def callback_numpy_plot(index, init_params):\n",
    "    plot_title = \"Iteration {:05}\".format(index)\n",
    "    file_name = \"numpy_model_{:05}.png\".format(index//1)\n",
    "    file_path = os.path.join(OUTPUT_DIR, file_name)\n",
    "    act = model.forward_prop(np.transpose(grid_2d),train_model=False)\n",
    "    prediction_probs = act[\"A\" + str(len(model.layer_names))]\n",
    "    prediction_probs = prediction_probs.reshape(prediction_probs.shape[1], 1)\n",
    "    make_plot(X_te, y_te, plot_title, file_name=file_path, XX=XX, YY=YY, preds=prediction_probs, dark=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "136ed99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.reset()\n",
    "model1.add(\"dense1\",X_tr.shape[1],500,\"relu\")\n",
    "model1.add(\"dense2\",500,250,\"relu\")\n",
    "model1.add(\"dense3\",250,150,\"relu\")\n",
    "model1.add(\"dense4\",150,100,\"tanh\")\n",
    "model1.add(\"dense5\",100,60,\"tanh\")\n",
    "model1.add(\"dense6\",60,30,\"relu\")\n",
    "model1.add(\"dense7\",30,15,\"tanh\")\n",
    "model1.add(\"dense8\",15,1,\"sigmoid\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "062d6def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (15,1) and (10,60000) not aligned: 1 (dim 1) != 10 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-4219300d8cdb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.005\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m35\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Adam\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Binary\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_tr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprint_cost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_numpy_plot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-6771d896c9cc>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, alpha, num_iter, optim, prob_type, mb, reg, lamb, alpha_decay, print_cost, callback)\u001b[0m\n\u001b[0;32m    103\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mvee\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mactivations_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_prop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini_batches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"MB_X\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvee\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward_prop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini_batches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"MB_Y\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvee\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprob_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivations_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlamb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[0moptim_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptim_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptim_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptim_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.005\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-6771d896c9cc>\u001b[0m in \u001b[0;36mbackward_prop\u001b[1;34m(self, y, prob_type, activations_cache, lamb, reg)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp_dA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mback_prop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp_dA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"A\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m       \u001b[0ml\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-efa93e4a4f82>\u001b[0m in \u001b[0;36mback_prop\u001b[1;34m(self, dA_prev, A_prev)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdZ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_reg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdZ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdZ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdZ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (15,1) and (10,60000) not aligned: 1 (dim 1) != 10 (dim 0)"
     ]
    }
   ],
   "source": [
    "model1.fit(X_tr,y_tr,0.005,35,\"Adam\",\"Binary\",mb=y_tr.shape[1],alpha_decay=True,print_cost=False,callback=callback_numpy_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deef79a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
